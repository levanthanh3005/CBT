{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad61740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn (from sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/ef/bcd79e8d59250d6e8478eb1290dc6e05be42b3be8a86e3954146adbc171a/scikit_learn-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
      "\u001b[K    100% |################################| 20.0MB 74kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1 (from scikit-learn->sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K    100% |################################| 25.9MB 52kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11 (from scikit-learn->sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/55/85/70c6602b078bd9e6f3da4f467047e906525c355a4dacd4f71b97a35d9897/joblib-1.0.1-py3-none-any.whl (303kB)\n",
      "\u001b[K    100% |################################| 307kB 4.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn->sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/e8/c216b9b60cbba4642d3ca1bae7a53daa0c24426f662e0e3ce3dc7f6caeaa/threadpoolctl-2.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: scipy, joblib, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.2 scipy-1.5.4 sklearn-0.0 threadpoolctl-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9270c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc.pilutil import imread\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import cv2\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy.random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "a35e673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=np.array([106,21,5,219,2,82])\n",
    "n = 100\n",
    "XTrain=np.zeros(shape=(n,8))\n",
    "YTrain=np.zeros(shape=(n))\n",
    "for i in range(0, n):\n",
    "    XTrain[i] = list(bin(int(i))[2:].zfill(8))\n",
    "    YTrain[i] = i%3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "410198f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 1., 0., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 1.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 1., 1.],\n",
       "       [0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 1., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 1., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 1., 1.],\n",
       "       [0., 0., 1., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 1., 1., 0., 1.],\n",
       "       [0., 0., 1., 0., 1., 1., 1., 0.],\n",
       "       [0., 0., 1., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 1., 0., 0., 1., 1.],\n",
       "       [0., 0., 1., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 1., 0., 1.],\n",
       "       [0., 0., 1., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 1., 1., 0., 1., 1., 1.],\n",
       "       [0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 0., 0., 1.],\n",
       "       [0., 0., 1., 1., 1., 0., 1., 0.],\n",
       "       [0., 0., 1., 1., 1., 0., 1., 1.],\n",
       "       [0., 0., 1., 1., 1., 1., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 0., 1.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 1.],\n",
       "       [0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 1., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 1., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 1., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 1., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 0., 1.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 1., 0., 0., 1., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 1., 0.],\n",
       "       [0., 1., 0., 1., 0., 1., 1., 1.],\n",
       "       [0., 1., 0., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 1., 0., 0., 1.],\n",
       "       [0., 1., 0., 1., 1., 0., 1., 0.],\n",
       "       [0., 1., 0., 1., 1., 0., 1., 1.],\n",
       "       [0., 1., 0., 1., 1., 1., 0., 0.],\n",
       "       [0., 1., 0., 1., 1., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 1., 1., 1., 0.],\n",
       "       [0., 1., 0., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "fb571ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "7b3745e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1.,\n",
       "       2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0.,\n",
       "       1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2.,\n",
       "       0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1.,\n",
       "       2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0.,\n",
       "       1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0., 1., 2., 0.])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "258ca51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBatch(xTrain, yTrain, batchSize):\n",
    "    inputLLs = []\n",
    "    inputRLs = []\n",
    "    targetLs = []\n",
    "    gr0Index = 0\n",
    "    gr1Index = 1\n",
    "    classes = np.unique(yTrain)\n",
    "#     print(\"classes:\",classes)\n",
    "    chooseDiffClasses = [0,0]\n",
    "    chooseDiffClasses[0] = rng.choice(classes)\n",
    "    chooseDiffClasses[1] = rng.choice([i for i in classes if i not in [chooseDiffClasses[0]]])\n",
    "    \n",
    "    chooseSameClasses = rng.choice(classes)\n",
    "    \n",
    "    numPerChoose = batchSize // 2\n",
    "\n",
    "#     print(\"chooseDiffClasses:\",chooseDiffClasses)\n",
    "#     print(\"chooseSameClasses:\",chooseSameClasses)\n",
    "    \n",
    "    #For same class\n",
    "#     print(\"For same class\")\n",
    "    \n",
    "    indexSCLs = np.where(yTrain==chooseSameClasses)[0]\n",
    "    rng.shuffle(indexSCLs)\n",
    "#     print(\"indexSCLs:\",indexSCLs)\n",
    "    \n",
    "    indexSC1 = rng.choice(indexSCLs[0:len(indexSCLs)//2],numPerChoose)\n",
    "    indexSC2 = rng.choice(indexSCLs[len(indexSCLs)//2:len(indexSCLs)],numPerChoose)\n",
    "#     print(\"indexSC1:\",indexSC1)\n",
    "#     print(\"indexSC2:\",indexSC2)\n",
    "    inputLLs = xTrain[indexSC1]\n",
    "    inputRLs = xTrain[indexSC2]\n",
    "    targetLs = np.full((1, numPerChoose), 1)[0]\n",
    "    \n",
    "#     print(inputLLs)\n",
    "#     print(inputRLs)\n",
    "#     print(targetLs)\n",
    "    \n",
    "    #For diff classes\n",
    "#     print(\"For diff class\")\n",
    "\n",
    "    indexSC1Ls = np.where(yTrain==chooseDiffClasses[0])[0]\n",
    "    rng.shuffle(indexSC1Ls)\n",
    "    indexSC2Ls = np.where(yTrain==chooseDiffClasses[1])[0]\n",
    "    rng.shuffle(indexSC2Ls)\n",
    "    \n",
    "    indexSC1 = rng.choice(indexSC1Ls,numPerChoose)\n",
    "    indexSC2 = rng.choice(indexSC2Ls,numPerChoose)\n",
    "    \n",
    "    inputLLs = np.append(inputLLs, xTrain[indexSC1], axis=0)\n",
    "    inputRLs = np.append(inputRLs, xTrain[indexSC2], axis=0)\n",
    "    targetLs = np.append(targetLs,np.full((1, numPerChoose), 0)[0])\n",
    "#     print(inputLLs)\n",
    "#     print(inputRLs)\n",
    "#     print(targetLs)\n",
    "    \n",
    "#     for i in choosedClasses:\n",
    "        \n",
    "#     for i in range(0, len(yTrain)):\n",
    "#         for j in range(i+1, len(yTrain)):\n",
    "#             ck = int(yTrain[i]==yTrain[j])\n",
    "# #             print(xTrain[i].reshape(8,1))\n",
    "#             inputLLs.append(xTrain[i].reshape(8,1))\n",
    "#             inputRLs.append(xTrain[j].reshape(8,1))\n",
    "# #             print(yTrain[i],\" \",yTrain[j],\" \",ck)\n",
    "#             targetLs.append(ck)\n",
    "    inputLLs = inputLLs.reshape(inputLLs.shape[0],8,1)\n",
    "    inputRLs = inputRLs.reshape(inputRLs.shape[0],8,1)\n",
    "\n",
    "    return ((inputLLs, inputRLs), targetLs)\n",
    "# \n",
    "(inputs,targets) = generateBatch(XTrain,YTrain,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "bb13a5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 1)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "0709b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have Weight matrix, W, d x z\n",
    "model = linear_model.LogisticRegression(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "W = model.coef_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "abdfcff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "3088eb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_37\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           [(None, 8, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           [(None, 8, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_19 (Sequential)      (None, 3)            159         input_39[0][0]                   \n",
      "                                                                 input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 3)            0           sequential_19[0][0]              \n",
      "                                                                 sequential_19[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 1)            4           lambda_18[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 163\n",
      "Trainable params: 163\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_siamese_model((8, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "1e03ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 0.00006)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "5400085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandom(arr,excepts=[]):\n",
    "    return rng.choice([i for i in arr if i not in excepts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "565c941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 8, 1)\n",
      "(20, 8, 1)\n",
      "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0].shape)\n",
    "print(inputs[1].shape)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "c9dcb2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697365403175354\n",
      "0.6914330124855042\n",
      "0.6922457218170166\n",
      "0.6959626078605652\n",
      "0.6936318278312683\n",
      "0.6934208869934082\n",
      "0.6929982304573059\n",
      "0.6979981660842896\n",
      "0.6943879127502441\n",
      "0.6940805315971375\n",
      "0.6925228834152222\n",
      "0.6925780177116394\n",
      "0.6891199946403503\n",
      "0.6936677694320679\n",
      "0.6934161186218262\n",
      "0.692773699760437\n",
      "0.6949936747550964\n",
      "0.6962010264396667\n",
      "0.6943359971046448\n",
      "0.6949589848518372\n",
      "0.6922491192817688\n",
      "0.6933517456054688\n",
      "0.6904087066650391\n",
      "0.6958338618278503\n",
      "0.6958473324775696\n",
      "0.6942882537841797\n",
      "0.6935323476791382\n",
      "0.6921451687812805\n",
      "0.691379725933075\n",
      "0.6888753771781921\n",
      "0.6948295831680298\n",
      "0.6919615864753723\n",
      "0.6958943605422974\n",
      "0.6927794218063354\n",
      "0.6974552869796753\n",
      "0.6926974058151245\n",
      "0.6894570589065552\n",
      "0.6923429369926453\n",
      "0.6956990957260132\n",
      "0.6955528259277344\n",
      "0.6968340873718262\n",
      "0.6930042505264282\n",
      "0.6949253082275391\n",
      "0.6915671825408936\n",
      "0.6932748556137085\n",
      "0.6897072792053223\n",
      "0.6961031556129456\n",
      "0.6926445364952087\n",
      "0.6944260597229004\n",
      "0.6927586793899536\n",
      "0.6964435577392578\n",
      "0.693557858467102\n",
      "0.6936715841293335\n",
      "0.6938236355781555\n",
      "0.6909194588661194\n",
      "0.6939758658409119\n",
      "0.6924808025360107\n",
      "0.6915826797485352\n",
      "0.6909590363502502\n",
      "0.6930620670318604\n",
      "0.6918702721595764\n",
      "0.6928447484970093\n",
      "0.6940800547599792\n",
      "0.6943901181221008\n",
      "0.6925419569015503\n",
      "0.693689227104187\n",
      "0.6928122639656067\n",
      "0.6923627853393555\n",
      "0.6911357641220093\n",
      "0.6917673349380493\n",
      "0.6926971077919006\n",
      "0.69706791639328\n",
      "0.6930605173110962\n",
      "0.6934512853622437\n",
      "0.6903537511825562\n",
      "0.6914879679679871\n",
      "0.6923763751983643\n",
      "0.6928256750106812\n",
      "0.6913729906082153\n",
      "0.6928878426551819\n",
      "0.6959052085876465\n",
      "0.697093665599823\n",
      "0.6927808523178101\n",
      "0.694205641746521\n",
      "0.6921812891960144\n",
      "0.6949955224990845\n",
      "0.6942221522331238\n",
      "0.6921141743659973\n",
      "0.6931118965148926\n",
      "0.6969280242919922\n",
      "0.6953233480453491\n",
      "0.6963781118392944\n",
      "0.6967089772224426\n",
      "0.6936289668083191\n",
      "0.690903902053833\n",
      "0.6930257081985474\n",
      "0.693341076374054\n",
      "0.6971535682678223\n",
      "0.6964277029037476\n",
      "0.6954636573791504\n",
      "0.6928502917289734\n",
      "0.6901372671127319\n",
      "0.6977928876876831\n",
      "0.6949425935745239\n",
      "0.69172203540802\n",
      "0.6946375966072083\n",
      "0.6882718801498413\n",
      "0.6944247484207153\n",
      "0.6893072128295898\n",
      "0.6896858811378479\n",
      "0.6927357912063599\n",
      "0.6922231912612915\n",
      "0.6959860920906067\n",
      "0.6963738799095154\n",
      "0.6962787508964539\n",
      "0.6951533555984497\n",
      "0.6956900954246521\n",
      "0.6927186250686646\n",
      "0.6897745132446289\n",
      "0.6948046088218689\n",
      "0.695980429649353\n",
      "0.6974593997001648\n",
      "0.6948965787887573\n",
      "0.6949692964553833\n",
      "0.6962167024612427\n",
      "0.6925321817398071\n",
      "0.6946749091148376\n",
      "0.690771222114563\n",
      "0.6898552775382996\n",
      "0.6964677572250366\n",
      "0.6927515864372253\n",
      "0.6895126104354858\n",
      "0.6905204057693481\n",
      "0.6922351121902466\n",
      "0.6921615600585938\n",
      "0.6920645236968994\n",
      "0.6903395652770996\n",
      "0.6953297257423401\n",
      "0.6916733384132385\n",
      "0.6898621320724487\n",
      "0.691813588142395\n",
      "0.6932084560394287\n",
      "0.6942812204360962\n",
      "0.689886748790741\n",
      "0.6893056035041809\n",
      "0.6921619176864624\n",
      "0.6983014345169067\n",
      "0.6910988688468933\n",
      "0.6959705352783203\n",
      "0.6933268904685974\n",
      "0.6932064294815063\n",
      "0.6913074254989624\n",
      "0.6926746368408203\n",
      "0.6930395364761353\n",
      "0.6973012685775757\n",
      "0.6926509141921997\n",
      "0.6879299879074097\n",
      "0.6947017908096313\n",
      "0.6920328140258789\n",
      "0.6946278810501099\n",
      "0.6941497921943665\n",
      "0.6922444105148315\n",
      "0.6902148723602295\n",
      "0.6929267644882202\n",
      "0.6900985240936279\n",
      "0.6923123598098755\n",
      "0.6937602162361145\n",
      "0.6911508440971375\n",
      "0.6917122602462769\n",
      "0.6918746829032898\n",
      "0.6902492046356201\n",
      "0.6957133412361145\n",
      "0.6905239224433899\n",
      "0.6941429376602173\n",
      "0.6932998299598694\n",
      "0.6935697793960571\n",
      "0.6948263049125671\n",
      "0.6906097531318665\n",
      "0.6932247877120972\n",
      "0.6925643682479858\n",
      "0.6948744654655457\n",
      "0.6917025446891785\n",
      "0.6886954307556152\n",
      "0.6929401159286499\n",
      "0.6948034167289734\n",
      "0.6941080093383789\n",
      "0.6971574425697327\n",
      "0.6915909647941589\n",
      "0.6888924837112427\n",
      "0.6952455639839172\n",
      "0.6933180689811707\n",
      "0.690627932548523\n",
      "0.6877351999282837\n",
      "0.6906152963638306\n",
      "0.6936008334159851\n",
      "0.6934970021247864\n",
      "0.6901564598083496\n",
      "0.692668080329895\n",
      "0.6944682002067566\n",
      "0.6924991607666016\n",
      "0.6924871206283569\n",
      "0.6945245862007141\n",
      "0.6898815035820007\n",
      "0.6942862272262573\n",
      "0.6937460899353027\n",
      "0.6924098134040833\n",
      "0.6899861097335815\n",
      "0.6915440559387207\n",
      "0.6936538815498352\n",
      "0.6937267184257507\n",
      "0.6935650110244751\n",
      "0.6908491849899292\n",
      "0.6959737539291382\n",
      "0.6938260793685913\n",
      "0.6972590684890747\n",
      "0.6890701055526733\n",
      "0.6930109858512878\n",
      "0.6914232969284058\n",
      "0.6955326199531555\n",
      "0.6923472285270691\n",
      "0.6930665373802185\n",
      "0.6932991147041321\n",
      "0.6932497024536133\n",
      "0.6911252737045288\n",
      "0.6942940950393677\n",
      "0.6926578283309937\n",
      "0.6981208920478821\n",
      "0.691543459892273\n",
      "0.6895942687988281\n",
      "0.6963974237442017\n",
      "0.6968428492546082\n",
      "0.6897295713424683\n",
      "0.6907174587249756\n",
      "0.6922928094863892\n",
      "0.6927352547645569\n",
      "0.6925169229507446\n",
      "0.6930280923843384\n",
      "0.6915053129196167\n",
      "0.6914811730384827\n",
      "0.694756269454956\n",
      "0.6964726448059082\n",
      "0.6882534623146057\n",
      "0.6900890469551086\n",
      "0.693892776966095\n",
      "0.697333037853241\n",
      "0.6886708736419678\n",
      "0.6921291351318359\n",
      "0.693544864654541\n",
      "0.6925593614578247\n",
      "0.6967663764953613\n",
      "0.6927553415298462\n",
      "0.6949635744094849\n",
      "0.6932500600814819\n",
      "0.6948381662368774\n",
      "0.6914710998535156\n",
      "0.6924597024917603\n",
      "0.6901718378067017\n",
      "0.6938620805740356\n",
      "0.6918772459030151\n",
      "0.6914992332458496\n",
      "0.69507896900177\n",
      "0.6943739652633667\n",
      "0.6915484666824341\n",
      "0.6954379081726074\n",
      "0.6975831985473633\n",
      "0.6979922652244568\n",
      "0.6914215087890625\n",
      "0.6910427808761597\n",
      "0.6940097808837891\n",
      "0.6908890008926392\n",
      "0.6917582750320435\n",
      "0.693159818649292\n",
      "0.6907066702842712\n",
      "0.6931358575820923\n",
      "0.6902683973312378\n",
      "0.6933997869491577\n",
      "0.6892954707145691\n",
      "0.6911152601242065\n",
      "0.6942508816719055\n",
      "0.6950014233589172\n",
      "0.6963828802108765\n",
      "0.6945369243621826\n",
      "0.6931039690971375\n",
      "0.6895400285720825\n",
      "0.691418468952179\n",
      "0.6931712031364441\n",
      "0.6973594427108765\n",
      "0.691785454750061\n",
      "0.6889013051986694\n",
      "0.6911897659301758\n",
      "0.6927775144577026\n",
      "0.6925516128540039\n",
      "0.6907609701156616\n",
      "0.6900855302810669\n",
      "0.6933760643005371\n",
      "0.689488410949707\n",
      "0.694337010383606\n",
      "0.6959513425827026\n",
      "0.6939128637313843\n",
      "0.6905407309532166\n",
      "0.6950655579566956\n",
      "0.6929311156272888\n",
      "0.6941903233528137\n",
      "0.6950814127922058\n",
      "0.6934664249420166\n",
      "0.6936808824539185\n",
      "0.6909193992614746\n",
      "0.6939634084701538\n",
      "0.6909015774726868\n",
      "0.6892352104187012\n",
      "0.6948818564414978\n",
      "0.694658637046814\n",
      "0.6891847848892212\n",
      "0.6947547793388367\n",
      "0.6941412687301636\n",
      "0.689745306968689\n",
      "0.690130352973938\n",
      "0.6910246014595032\n",
      "0.694482684135437\n",
      "0.694819450378418\n",
      "0.6957190632820129\n",
      "0.692960798740387\n",
      "0.692611575126648\n",
      "0.6913021206855774\n",
      "0.6914467811584473\n",
      "0.6949916481971741\n",
      "0.6955412030220032\n",
      "0.6972143054008484\n",
      "0.689590334892273\n",
      "0.6915169954299927\n",
      "0.6938624382019043\n",
      "0.6950566172599792\n",
      "0.6935619711875916\n",
      "0.6941992044448853\n",
      "0.6917526721954346\n",
      "0.692785382270813\n",
      "0.6939011216163635\n",
      "0.6943201422691345\n",
      "0.6919733285903931\n",
      "0.6903178095817566\n",
      "0.6940361261367798\n",
      "0.6913414001464844\n",
      "0.6888889074325562\n",
      "0.6932394504547119\n",
      "0.6903732419013977\n",
      "0.6920133233070374\n",
      "0.6926575899124146\n",
      "0.6942999958992004\n",
      "0.6954392194747925\n",
      "0.6969943046569824\n",
      "0.6946975588798523\n",
      "0.6914863586425781\n",
      "0.6926159858703613\n",
      "0.6953756213188171\n",
      "0.6961249113082886\n",
      "0.693869411945343\n",
      "0.6933680176734924\n",
      "0.6955607533454895\n",
      "0.6911346912384033\n",
      "0.6930059194564819\n",
      "0.6923254728317261\n",
      "0.6915944814682007\n",
      "0.694456934928894\n",
      "0.6892019510269165\n",
      "0.6936334371566772\n",
      "0.69548499584198\n",
      "0.6932867169380188\n",
      "0.6949597597122192\n",
      "0.6940537691116333\n",
      "0.6939018964767456\n",
      "0.6971511840820312\n",
      "0.696802020072937\n",
      "0.6951612234115601\n",
      "0.6930524110794067\n",
      "0.6925879716873169\n",
      "0.6919859647750854\n",
      "0.6902481317520142\n",
      "0.6903573870658875\n",
      "0.6961365938186646\n",
      "0.6911571621894836\n",
      "0.687783420085907\n",
      "0.697123110294342\n",
      "0.6932593584060669\n",
      "0.6908844113349915\n",
      "0.692857563495636\n",
      "0.6951037645339966\n",
      "0.6925848126411438\n",
      "0.69587242603302\n",
      "0.691271185874939\n",
      "0.6881930232048035\n",
      "0.6951183080673218\n",
      "0.6939338445663452\n",
      "0.6905437707901001\n",
      "0.6952188611030579\n",
      "0.6947835683822632\n",
      "0.6936772465705872\n",
      "0.6881812810897827\n",
      "0.6911864280700684\n",
      "0.6909832954406738\n",
      "0.6896885633468628\n",
      "0.691822350025177\n",
      "0.6939116716384888\n",
      "0.6933094263076782\n",
      "0.6964141130447388\n",
      "0.6957727670669556\n",
      "0.6937233805656433\n",
      "0.6928315162658691\n",
      "0.691199004650116\n",
      "0.6942020654678345\n",
      "0.6923710107803345\n",
      "0.6899675726890564\n",
      "0.6941558122634888\n",
      "0.6960397958755493\n",
      "0.6942229270935059\n",
      "0.6930626034736633\n",
      "0.6935322284698486\n",
      "0.6935938596725464\n",
      "0.6917886734008789\n",
      "0.6935693621635437\n",
      "0.6876013875007629\n",
      "0.6921678781509399\n",
      "0.692661464214325\n",
      "0.6931794881820679\n",
      "0.693374752998352\n",
      "0.6919263601303101\n",
      "0.6890857219696045\n",
      "0.6961221694946289\n",
      "0.6929468512535095\n",
      "0.6923007369041443\n",
      "0.6936818957328796\n",
      "0.6942432522773743\n",
      "0.6922429800033569\n",
      "0.6893537640571594\n",
      "0.6959498524665833\n",
      "0.6919505596160889\n",
      "0.6909838914871216\n",
      "0.6920191049575806\n",
      "0.6935907602310181\n",
      "0.695736289024353\n",
      "0.6939538717269897\n",
      "0.696738600730896\n",
      "0.6909953355789185\n",
      "0.6931840777397156\n",
      "0.6940266489982605\n",
      "0.6924048662185669\n",
      "0.6909711956977844\n",
      "0.6952200531959534\n",
      "0.696103572845459\n",
      "0.6964016556739807\n",
      "0.6955564022064209\n",
      "0.6945770382881165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6943153142929077\n",
      "0.6954353451728821\n",
      "0.6866881847381592\n",
      "0.6915132403373718\n",
      "0.692578911781311\n",
      "0.6900246739387512\n",
      "0.6933035850524902\n",
      "0.6942970752716064\n",
      "0.6950330138206482\n",
      "0.6920219659805298\n",
      "0.6971955299377441\n",
      "0.6929251551628113\n",
      "0.69373619556427\n",
      "0.6941820383071899\n",
      "0.6953469514846802\n",
      "0.691438615322113\n",
      "0.6953074336051941\n",
      "0.691170871257782\n",
      "0.6917895674705505\n",
      "0.6947712898254395\n",
      "0.6914323568344116\n",
      "0.6918746829032898\n",
      "0.6931963562965393\n",
      "0.692438006401062\n",
      "0.6887749433517456\n",
      "0.694183349609375\n",
      "0.6907772421836853\n",
      "0.6898356676101685\n",
      "0.696733832359314\n",
      "0.6959144473075867\n",
      "0.6941660642623901\n",
      "0.6906856894493103\n",
      "0.6922159790992737\n",
      "0.6914269328117371\n",
      "0.6921359300613403\n",
      "0.694022536277771\n",
      "0.6915342211723328\n",
      "0.6933115720748901\n",
      "0.6945303082466125\n",
      "0.6925092935562134\n",
      "0.6921585202217102\n",
      "0.6943877935409546\n",
      "0.6943848729133606\n",
      "0.6961197853088379\n",
      "0.6938718557357788\n",
      "0.6915432810783386\n",
      "0.6932536959648132\n",
      "0.6940523386001587\n",
      "0.6932834982872009\n",
      "0.6931926608085632\n",
      "0.6914759874343872\n",
      "0.6922845244407654\n",
      "0.6917956471443176\n",
      "0.6905461549758911\n",
      "0.6947864294052124\n",
      "0.6919683218002319\n",
      "0.6910021901130676\n",
      "0.6918051838874817\n",
      "0.6913525462150574\n",
      "0.6935690641403198\n",
      "0.6911069750785828\n",
      "0.6896863579750061\n",
      "0.6924121975898743\n",
      "0.6932978630065918\n",
      "0.6936103105545044\n",
      "0.6913418769836426\n",
      "0.6939350366592407\n",
      "0.693110466003418\n",
      "0.6948776245117188\n",
      "0.6889753341674805\n",
      "0.6902490854263306\n",
      "0.6925029754638672\n",
      "0.6926592588424683\n",
      "0.6953150033950806\n",
      "0.6946901679039001\n",
      "0.6927080750465393\n",
      "0.6962056756019592\n",
      "0.6891791224479675\n",
      "0.6980339884757996\n",
      "0.6925681233406067\n",
      "0.6948716640472412\n",
      "0.690050482749939\n",
      "0.690226674079895\n",
      "0.6941903233528137\n",
      "0.6921154260635376\n",
      "0.6939791440963745\n",
      "0.6928809285163879\n",
      "0.6918895840644836\n",
      "0.6958566904067993\n",
      "0.6941625475883484\n",
      "0.6906293630599976\n",
      "0.6916522979736328\n",
      "0.6898252367973328\n",
      "0.6956561207771301\n",
      "0.6925458908081055\n",
      "0.6941118836402893\n",
      "0.6924669742584229\n",
      "0.6947983503341675\n",
      "0.6918579339981079\n",
      "0.6911131143569946\n",
      "0.6923404932022095\n",
      "0.693823516368866\n",
      "0.6934630274772644\n",
      "0.6931138038635254\n",
      "0.6945021748542786\n",
      "0.6912420988082886\n",
      "0.6932128667831421\n",
      "0.6918709874153137\n",
      "0.6945028901100159\n",
      "0.6946846842765808\n",
      "0.6970118284225464\n",
      "0.6930407285690308\n",
      "0.6969741582870483\n",
      "0.690139651298523\n",
      "0.6927353739738464\n",
      "0.6904290914535522\n",
      "0.6946704983711243\n",
      "0.696888267993927\n",
      "0.6906141042709351\n",
      "0.6967934370040894\n",
      "0.6927369236946106\n",
      "0.6908750534057617\n",
      "0.696395754814148\n",
      "0.691877007484436\n",
      "0.6950519680976868\n",
      "0.6946651935577393\n",
      "0.6944236755371094\n",
      "0.6921280026435852\n",
      "0.6919623613357544\n",
      "0.6905937194824219\n",
      "0.689896285533905\n",
      "0.6920408010482788\n",
      "0.6922231316566467\n",
      "0.6927608251571655\n",
      "0.6952872276306152\n",
      "0.6938828229904175\n",
      "0.6926889419555664\n",
      "0.6923922300338745\n",
      "0.6945251822471619\n",
      "0.6921941041946411\n",
      "0.6870884895324707\n",
      "0.6933276057243347\n",
      "0.6954910159111023\n",
      "0.688555896282196\n",
      "0.6913243532180786\n",
      "0.6913703083992004\n",
      "0.6949553489685059\n",
      "0.6901928186416626\n",
      "0.6932368874549866\n",
      "0.6929338574409485\n",
      "0.694379448890686\n",
      "0.6933160424232483\n",
      "0.6927834153175354\n",
      "0.6896466016769409\n",
      "0.6913679838180542\n",
      "0.6921085119247437\n",
      "0.6961423754692078\n",
      "0.6906638145446777\n",
      "0.6905521154403687\n",
      "0.6921371817588806\n",
      "0.6937916278839111\n",
      "0.6955775618553162\n",
      "0.6889487504959106\n",
      "0.6910505890846252\n",
      "0.6910738348960876\n",
      "0.6954701542854309\n",
      "0.6955755949020386\n",
      "0.6896525621414185\n",
      "0.6936032176017761\n",
      "0.6912347078323364\n",
      "0.694604218006134\n",
      "0.6908366680145264\n",
      "0.6903650164604187\n",
      "0.6949715614318848\n",
      "0.6925021409988403\n",
      "0.6951406002044678\n",
      "0.6955198049545288\n",
      "0.6881277561187744\n",
      "0.6945386528968811\n",
      "0.6975431442260742\n",
      "0.690338134765625\n",
      "0.6904398798942566\n",
      "0.6868945956230164\n",
      "0.6923151016235352\n",
      "0.693071186542511\n",
      "0.6933538913726807\n",
      "0.69340980052948\n",
      "0.6931533813476562\n",
      "0.6926474571228027\n",
      "0.6948091387748718\n",
      "0.6889567375183105\n",
      "0.6960516571998596\n",
      "0.6943641304969788\n",
      "0.6943889856338501\n",
      "0.691761314868927\n",
      "0.6959143877029419\n",
      "0.6951261758804321\n",
      "0.6932940483093262\n",
      "0.693458616733551\n",
      "0.6937519311904907\n",
      "0.6941152811050415\n",
      "0.6927520036697388\n",
      "0.6920958757400513\n",
      "0.6932322382926941\n",
      "0.6938141584396362\n",
      "0.6981075406074524\n",
      "0.6916103363037109\n",
      "0.6932746171951294\n",
      "0.692251443862915\n",
      "0.6921766400337219\n",
      "0.6958346366882324\n",
      "0.6903294324874878\n",
      "0.691875696182251\n",
      "0.6907731890678406\n",
      "0.6870811581611633\n",
      "0.692396342754364\n",
      "0.6933447122573853\n",
      "0.6900840997695923\n",
      "0.6977709531784058\n",
      "0.6946439743041992\n",
      "0.6927811503410339\n",
      "0.6948715448379517\n",
      "0.691230297088623\n",
      "0.6903608441352844\n",
      "0.687141478061676\n",
      "0.6931702494621277\n",
      "0.6911783218383789\n",
      "0.6966120004653931\n",
      "0.6934131383895874\n",
      "0.6912297606468201\n",
      "0.693038821220398\n",
      "0.6970966458320618\n",
      "0.6962532997131348\n",
      "0.6929354071617126\n",
      "0.6954900622367859\n",
      "0.689093828201294\n",
      "0.6958832740783691\n",
      "0.6953325271606445\n",
      "0.696251392364502\n",
      "0.6905404329299927\n",
      "0.6971237659454346\n",
      "0.6911624670028687\n",
      "0.6938632130622864\n",
      "0.6964297890663147\n",
      "0.6890559196472168\n",
      "0.6932836771011353\n",
      "0.6916661858558655\n",
      "0.6940687894821167\n",
      "0.6908594965934753\n",
      "0.6919604539871216\n",
      "0.6940950155258179\n",
      "0.6952212452888489\n",
      "0.6903437376022339\n",
      "0.6932674050331116\n",
      "0.6926138997077942\n",
      "0.6936480402946472\n",
      "0.6912153959274292\n",
      "0.6932982206344604\n",
      "0.6934605240821838\n",
      "0.693216860294342\n",
      "0.6919811367988586\n",
      "0.693812370300293\n",
      "0.6961802840232849\n",
      "0.6915606260299683\n",
      "0.6959022283554077\n",
      "0.6908597946166992\n",
      "0.6911399960517883\n",
      "0.6936150789260864\n",
      "0.6945117712020874\n",
      "0.6917890906333923\n",
      "0.693861186504364\n",
      "0.6892924308776855\n",
      "0.6911826133728027\n",
      "0.6945223212242126\n",
      "0.6969032287597656\n",
      "0.6934558153152466\n",
      "0.6958233118057251\n",
      "0.6926606893539429\n",
      "0.6936949491500854\n",
      "0.6906179189682007\n",
      "0.6910880208015442\n",
      "0.6945384740829468\n",
      "0.6910545229911804\n",
      "0.6954953670501709\n",
      "0.6966809034347534\n",
      "0.6956294775009155\n",
      "0.6945475935935974\n",
      "0.693473219871521\n",
      "0.6942590475082397\n",
      "0.6877274513244629\n",
      "0.692676842212677\n",
      "0.6898592710494995\n",
      "0.6928415894508362\n",
      "0.6905628442764282\n",
      "0.6872664093971252\n",
      "0.6927106976509094\n",
      "0.6877983808517456\n",
      "0.6925188302993774\n",
      "0.6929460167884827\n",
      "0.6906023025512695\n",
      "0.6929342150688171\n",
      "0.6936699748039246\n",
      "0.6935660243034363\n",
      "0.6933121085166931\n",
      "0.6930351853370667\n",
      "0.6931500434875488\n",
      "0.6920210719108582\n",
      "0.6901012659072876\n",
      "0.6946128010749817\n",
      "0.6925984025001526\n",
      "0.6921845078468323\n",
      "0.6944743394851685\n",
      "0.691382110118866\n",
      "0.6929141879081726\n",
      "0.6897061467170715\n",
      "0.6956568360328674\n",
      "0.6926223039627075\n",
      "0.695696234703064\n",
      "0.6921275854110718\n",
      "0.6902735829353333\n",
      "0.6896486282348633\n",
      "0.6956921815872192\n",
      "0.693048357963562\n",
      "0.6918411254882812\n",
      "0.6887332201004028\n",
      "0.6944576501846313\n",
      "0.68764328956604\n",
      "0.6943150758743286\n",
      "0.6907713413238525\n",
      "0.6924212574958801\n",
      "0.6912612915039062\n",
      "0.6973438858985901\n",
      "0.694015383720398\n",
      "0.693720817565918\n",
      "0.6907213926315308\n",
      "0.6902360916137695\n",
      "0.6927670836448669\n",
      "0.6879370808601379\n",
      "0.6914953589439392\n",
      "0.6916459798812866\n",
      "0.6943804621696472\n",
      "0.6952275037765503\n",
      "0.6906342506408691\n",
      "0.6945700645446777\n",
      "0.6934263706207275\n",
      "0.6963184475898743\n",
      "0.6940664649009705\n",
      "0.6883198022842407\n",
      "0.6901857852935791\n",
      "0.6891922950744629\n",
      "0.6938024759292603\n",
      "0.6946160197257996\n",
      "0.6949081420898438\n",
      "0.6901085376739502\n",
      "0.6921303868293762\n",
      "0.688731849193573\n",
      "0.6922683119773865\n",
      "0.6917179822921753\n",
      "0.6924614906311035\n",
      "0.6895276308059692\n",
      "0.69233238697052\n",
      "0.6957371830940247\n",
      "0.6939417719841003\n",
      "0.6963390111923218\n",
      "0.6940940022468567\n",
      "0.6940432786941528\n",
      "0.6906889081001282\n",
      "0.6937727928161621\n",
      "0.6944406628608704\n",
      "0.6889543533325195\n",
      "0.6923869848251343\n",
      "0.694284200668335\n",
      "0.6935076117515564\n",
      "0.6927512884140015\n",
      "0.6912614107131958\n",
      "0.6970783472061157\n",
      "0.6907682418823242\n",
      "0.691332995891571\n",
      "0.6909282803535461\n",
      "0.6927976608276367\n",
      "0.6927580833435059\n",
      "0.6925617456436157\n",
      "0.6934818029403687\n",
      "0.6924680471420288\n",
      "0.6917366981506348\n",
      "0.6908445358276367\n",
      "0.6949673891067505\n",
      "0.6935291290283203\n",
      "0.6955790519714355\n",
      "0.6924880743026733\n",
      "0.692385733127594\n",
      "0.6918408274650574\n",
      "0.692442774772644\n",
      "0.6925935745239258\n",
      "0.6980713605880737\n",
      "0.6881163716316223\n",
      "0.6929854154586792\n",
      "0.6920698881149292\n",
      "0.692269504070282\n",
      "0.6944684386253357\n",
      "0.6944689750671387\n",
      "0.6934642195701599\n",
      "0.6930379271507263\n",
      "0.6929143667221069\n",
      "0.6943753957748413\n",
      "0.6899258494377136\n",
      "0.6940779089927673\n",
      "0.694331705570221\n",
      "0.6909774541854858\n",
      "0.693574070930481\n",
      "0.6937483549118042\n",
      "0.6945257186889648\n",
      "0.692650318145752\n",
      "0.6921590566635132\n",
      "0.6936262845993042\n",
      "0.6899650692939758\n",
      "0.6887698173522949\n",
      "0.6935703754425049\n",
      "0.6908872127532959\n",
      "0.6936259269714355\n",
      "0.6929274201393127\n",
      "0.6910291910171509\n",
      "0.6913897395133972\n",
      "0.6919230222702026\n",
      "0.6889296770095825\n",
      "0.6930992007255554\n",
      "0.6920415163040161\n",
      "0.691785991191864\n",
      "0.698570191860199\n",
      "0.6938485503196716\n",
      "0.6948991417884827\n",
      "0.6913641095161438\n",
      "0.6933380961418152\n",
      "0.6910823583602905\n",
      "0.6948758959770203\n",
      "0.6923915147781372\n",
      "0.6929667592048645\n",
      "0.6908432245254517\n",
      "0.6944953799247742\n",
      "0.6963079571723938\n",
      "0.6930287480354309\n",
      "0.6895357370376587\n",
      "0.695748507976532\n",
      "0.6928088068962097\n",
      "0.6976050138473511\n",
      "0.6915871500968933\n",
      "0.6928989887237549\n",
      "0.6940525770187378\n",
      "0.6942051649093628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6929577589035034\n",
      "0.6894792318344116\n",
      "0.6899289488792419\n",
      "0.6946648359298706\n",
      "0.6936528086662292\n",
      "0.6909832954406738\n",
      "0.6945748925209045\n",
      "0.6938600540161133\n",
      "0.6928938031196594\n",
      "0.6936629414558411\n",
      "0.6923394203186035\n",
      "0.6928077936172485\n",
      "0.6915956735610962\n",
      "0.6880370378494263\n",
      "0.6945733428001404\n",
      "0.691504180431366\n",
      "0.6914125680923462\n",
      "0.6909200549125671\n",
      "0.6892444491386414\n",
      "0.6894286870956421\n",
      "0.694603443145752\n",
      "0.6919956803321838\n",
      "0.6969431638717651\n",
      "0.6939336657524109\n",
      "0.6918123960494995\n",
      "0.6923593878746033\n",
      "0.6940490007400513\n",
      "0.6944241523742676\n",
      "0.6904205083847046\n",
      "0.6891918182373047\n",
      "0.6927824020385742\n",
      "0.69124436378479\n",
      "0.6942868828773499\n",
      "0.697527289390564\n",
      "0.6892653703689575\n",
      "0.6953611373901367\n",
      "0.6943619847297668\n",
      "0.6904875040054321\n",
      "0.6911302804946899\n",
      "0.699741780757904\n",
      "0.697121798992157\n",
      "0.6910306215286255\n",
      "0.695184588432312\n",
      "0.6932190656661987\n",
      "0.6939131021499634\n",
      "0.6944392323493958\n",
      "0.6952594518661499\n",
      "0.6919782757759094\n",
      "0.6933215260505676\n",
      "0.6953575015068054\n",
      "0.690910816192627\n",
      "0.6920149922370911\n",
      "0.6939001083374023\n",
      "0.6932997703552246\n",
      "0.6941116452217102\n",
      "0.6927436590194702\n",
      "0.693155825138092\n",
      "0.6930286288261414\n",
      "0.6921913623809814\n",
      "0.6955106258392334\n",
      "0.6916600465774536\n",
      "0.6955728530883789\n",
      "0.6921720504760742\n",
      "0.6911677122116089\n",
      "0.6949427723884583\n",
      "0.6909078359603882\n",
      "0.6901483535766602\n",
      "0.6893731355667114\n",
      "0.6927942037582397\n",
      "0.693412184715271\n",
      "0.690768837928772\n",
      "0.6939151883125305\n",
      "0.6929737329483032\n",
      "0.6932286620140076\n",
      "0.6939534544944763\n",
      "0.6931867599487305\n",
      "0.691012978553772\n",
      "0.6917971968650818\n",
      "0.6953951120376587\n",
      "0.6923797726631165\n",
      "0.6904348134994507\n",
      "0.6966224908828735\n",
      "0.6911876797676086\n",
      "0.6948339939117432\n",
      "0.6956865191459656\n",
      "0.6900412440299988\n",
      "0.6945004463195801\n",
      "0.6923778653144836\n",
      "0.691907525062561\n",
      "0.690560519695282\n",
      "0.6968486309051514\n",
      "0.6922385692596436\n",
      "0.6897822618484497\n",
      "0.6923487782478333\n",
      "0.697481632232666\n",
      "0.6883164644241333\n",
      "0.6905285716056824\n",
      "0.6927083730697632\n",
      "0.688471794128418\n",
      "0.6926058530807495\n"
     ]
    }
   ],
   "source": [
    "epoch=1000\n",
    "batchSize=20\n",
    "for i in range(0,epoch):\n",
    "    (inputs,targets) = generateBatch(XTrain,YTrain,batchSize)\n",
    "    loss = model.train_on_batch(inputs, targets)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "d2575398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([1,2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "9ea2feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareArr(A,B):\n",
    "    number_of_equal_elements = np.sum(A==B)\n",
    "#     print(number_of_equal_elements)\n",
    "    total_elements = len(A)\n",
    "    percentage = number_of_equal_elements/total_elements\n",
    "    return (number_of_equal_elements,total_elements,percentage)\n",
    "\n",
    "def testOneShot():\n",
    "    accCount = 0\n",
    "    total = 0\n",
    "    testNum = 1\n",
    "    for i in range(0,testNum):\n",
    "        inputs, targets = generateBatch(XTrain,YTrain,batchSize)\n",
    "        probs = model.predict(inputs)\n",
    "#         print(probs.shape)\n",
    "        probs = probs.reshape(1,len(probs))[0]\n",
    "#         print(probs)\n",
    "        for j in range(0,len(probs)):\n",
    "            if (probs[j] < 0.5):\n",
    "                probs[j] = 0\n",
    "            else:\n",
    "                probs[j] = 1\n",
    "#         print(targets)\n",
    "#         print(probs)\n",
    "        (c,t,p) = compareArr(probs,targets)\n",
    "#         print(c,t,p)\n",
    "        accCount = accCount + c\n",
    "        total = total + t\n",
    "    print(accCount,total)\n",
    "    print(\"Percent:\", (accCount*100)/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "bf3a5622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 20\n",
      "Percent: 50.0\n"
     ]
    }
   ],
   "source": [
    "testOneShot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
